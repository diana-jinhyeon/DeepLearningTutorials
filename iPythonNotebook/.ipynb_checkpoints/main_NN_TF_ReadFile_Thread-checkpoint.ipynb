{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Trains the MNIST network using preloaded data in a constant.\n",
    "Run using bazel:\n",
    "bazel run -c opt \\\n",
    "    <...>/tensorflow/examples/how_tos/reading_data:fully_connected_preloaded\n",
    "or, if installed via pip:\n",
    "cd tensorflow/examples/how_tos/reading_data\n",
    "python fully_connected_preloaded.py\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.examples.tutorials.mnist import mnist\n",
    "\n",
    "\n",
    "# Basic model parameters as external flags.\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('num_epochs', 2, 'Number of epochs to run trainer.')\n",
    "flags.DEFINE_integer('hidden1', 128, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_integer('batch_size', 100, 'Batch size.  '\n",
    "                     'Must divide evenly into the dataset sizes.')\n",
    "flags.DEFINE_string('train_dir', '/tmp/data',\n",
    "                    'Directory to put the training data.')\n",
    "flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data '\n",
    "                     'for unit testing.')\n",
    "\n",
    "\n",
    "def run_training():\n",
    "  \"\"\"Train MNIST for a number of epochs.\"\"\"\n",
    "  # Get the sets of images and labels for training, validation, and\n",
    "  # test on MNIST.\n",
    "  data_sets = input_data.read_data_sets(FLAGS.train_dir, FLAGS.fake_data)\n",
    "\n",
    "  # Tell TensorFlow that the model will be built into the default Graph.\n",
    "  with tf.Graph().as_default():\n",
    "    with tf.name_scope('input'):\n",
    "      # Input data, pin to CPU because rest of pipeline is CPU-only\n",
    "      with tf.device('/cpu:0'):\n",
    "        input_images = tf.constant(data_sets.train.images)\n",
    "        input_labels = tf.constant(data_sets.train.labels)\n",
    "\n",
    "      image, label = tf.train.slice_input_producer(\n",
    "          [input_images, input_labels], num_epochs=FLAGS.num_epochs)\n",
    "      label = tf.cast(label, tf.int32)\n",
    "      images, labels = tf.train.batch(\n",
    "          [image, label], batch_size=FLAGS.batch_size)\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = mnist.inference(images, FLAGS.hidden1, FLAGS.hidden2)\n",
    "\n",
    "    # Add to the Graph the Ops for loss calculation.\n",
    "    loss = mnist.loss(logits, labels)\n",
    "\n",
    "    # Add to the Graph the Ops that calculate and apply gradients.\n",
    "    train_op = mnist.training(loss, FLAGS.learning_rate)\n",
    "\n",
    "    # Add the Op to compare the logits to the labels during evaluation.\n",
    "    eval_correct = mnist.evaluation(logits, labels)\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Create the op for initializing variables.\n",
    "    init_op = tf.group(tf.initialize_all_variables(),\n",
    "                       tf.initialize_local_variables())\n",
    "    # Create a session for running Ops on the Graph.\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Run the Op to initialize the variables.\n",
    "    sess.run(init_op)\n",
    "\n",
    "    # Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph) #/tmp/data\n",
    "\n",
    "    # Start input enqueue threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    # And then after everything is built, start the training loop.\n",
    "    try:\n",
    "      step = 0\n",
    "      while not coord.should_stop():\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Run one step of the model.\n",
    "        _, loss_value = sess.run([train_op, loss])\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        # Write the summaries and print an overview fairly often.\n",
    "        if step % 100 == 0:\n",
    "          # Print status to stdout.\n",
    "          print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value,\n",
    "                                                     duration))\n",
    "          # Update the events file.\n",
    "          summary_str = sess.run(summary_op)\n",
    "          summary_writer.add_summary(summary_str, step)\n",
    "          step += 1\n",
    "\n",
    "        # Save a checkpoint periodically.\n",
    "        if (step + 1) % 1000 == 0:\n",
    "          print('Saving')\n",
    "          saver.save(sess, FLAGS.train_dir, global_step=step)\n",
    "\n",
    "        step += 1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print('Saving')\n",
    "      saver.save(sess, FLAGS.train_dir, global_step=step)\n",
    "      print('Done training for %d epochs, %d steps.' % (FLAGS.num_epochs, step))\n",
    "    finally:\n",
    "      # When done, ask the threads to stop.\n",
    "      coord.request_stop()\n",
    "\n",
    "    # Wait for threads to finish.\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  run_training()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()\n",
    "#Contact GitHub API Training Shop Blog About\n",
    "#Â© 2016 GitHub, Inc. Terms Privacy Security Status Help"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
